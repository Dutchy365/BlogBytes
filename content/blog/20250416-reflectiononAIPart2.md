---
author: ""
title: "When chatbots feel human"
date: 2025-04-16
description: A personal reflection on AI 
tags:
- Artificial Intelligence
- chatbot
- ELIZA
thumbnail: /images/20250416ReflectiononAIpartPart2/00ReflectiononAIpart2.png
preview: /00ReflectiononAIpart2.png
images: 
- /00ReflectiononAIpart2.png
---

A couple of months ago I wrote my [first blog](/blog/20240923-reflectiononai/) as a reflection on AI. This second piece continues that exploration, this time focusing on the part that fascinates (and unsettles) me most: the feeling that chatbots are becoming human.

## AI at work vs. daily life
In my work, I encounter AI on a daily basisâ€”not just in the tools and technologies we use, but also in the enthusiasm of people who work with it. At the same time, I see a stark contrast in my personal life. Many people around me havenâ€™t really tried with AI at all. Some of them consciously avoid it, but many simply donâ€™t know how it could be useful to them.

Out of curiosity, I recently asked ChatGPT how AI could be used in personal contexts. I was surprised by its first two suggestions: emotional support and decision-making related to careers and relationships. Call me naive, but I expected something more practicalâ€”like planning a holiday or coming up with creative recipes. 

![chatgpt](/images/20250416ReflectiononAIpartPart2/chatgpt.png)

## New type of interaction
This type of use shifts the nature of human interaction. Where someone might once have turned to a friend, theyâ€™re now turning to a chatbot. It immediately brought to mind ELIZA, the chatbot created by Joseph Weizenbaum in 1966. Even back then, it was clear how quickly people began attributing human traits to a machine.


<iframe width="560" height="315" src="https://www.youtube.com/embed/RMK9AphfLco?si=phW-WPrqdRdKtS7h" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

## The ELIZA effect
Weizenbaum later warned about what became known as the ELIZA effect: our tendency to project human characteristics onto non-human systems. Nearly sixty years later, I see that same pattern. 
Todayâ€™s AI chatbots donâ€™t just repeat back your words. They engage, empathize, and adapt. Iâ€™ve already heard several stories of people using chatbots as personal coaches, companions, even therapists. These systems now have access to your most vulnerable thoughts (your anxieties, doubts, fears) and not just yours, but those of millions of people around the world.


## Time to pay attention
It raises an unsettling question: In a world that often feels isolating, are we turning to machines to feel seen, loved, and taken seriously?

Thereâ€™s a Dutch book that comes to mind: Je hebt wÃ©l iets te verbergen ("You actually _do_ have something to hide"), published in 2016. It argued for the importance of privacy at a time when we were just beginning to question what we shared online. The warnings back then were mostly about social media. But now, the line between private and public has blurred even further. Today, we donâ€™t just post pictures or thoughtsâ€”we pour our inner lives into these digital conversations. And we rarely stop to consider where that data goes, who sees it, or how the data might be used.

Thatâ€™s why I think itâ€™s time we reexamine the ELIZA effectâ€”not just as a psychological curiosity, but as a cultural signal. What does it mean to form emotional bonds with something that doesnâ€™t feel back? Shouldn't we be more aware of this phenomenon and make people more aware of it. How can we protect ourselves both from the emotional side effects as the possible use of the deeply personal data? 

Weâ€™re not just training AI. Itâ€™s training us too.



## Sources and recommendations 
* ðŸ“ºVideo: [The First Ever AI Chatbot: ELIZA (1966)](https://www.youtube.com/watch?v=8jGpkdPO-1Y)
* ðŸ“» Podcast episode (in Dutch) in conversation with Astrid Holleeder, from minute 50 to 57 an example regarding the ELIZA effect: [Daphne op Donderdag](https://open.spotify.com/episode/2O9W6kXj5AOVgZ4rctAKSu?si=etMG4RlJSjSk02XJ8EJiCA)
* ðŸ“° Article: [Nelson, J. (2025, April 15). OpenAIâ€™s ChatGPT-4.5 passes Turing Test with 73% success rate.](https://decrypt.co/314780/openais-gpt-4-5-passes-turing-test)
* ðŸ“˜ Book (in Dutch): [Martijn, M., en Tokmetzis, D. (2016). Je hebt wÃ©l iets te verbergen: over het levensbelang van privacy.](https://www.managementboek.nl/boek/9789083117614/je-hebt-wel-iets-te-verbergen-maurits-martijn)